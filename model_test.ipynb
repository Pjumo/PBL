{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9404,"status":"ok","timestamp":1713177301574,"user":{"displayName":"지찬웅","userId":"10324921424986400402"},"user_tz":-540},"id":"DZ98ZS0bbt49","outputId":"6e270016-a5a1-442e-d248-1f8f82ac6a1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1713185161440,"user":{"displayName":"지찬웅","userId":"10324921424986400402"},"user_tz":-540},"id":"SUpaugFob5Ku","outputId":"7d97ca13-81c0-466f-c3de-01c248119fdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/github/PBL\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/github/PBL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9l57rG9Zoud","outputId":"30b32a78-50cb-428a-81b8-547c6bc64d4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch 1 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 4.4691, Train Acc: 0.0274\n","Validation Loss: 4.1986, Validation Acc: 0.0457\n","Epoch 2 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 4.1591, Train Acc: 0.0531\n","Validation Loss: 3.9557, Validation Acc: 0.0743\n","Epoch 3 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.9780, Train Acc: 0.0725\n","Validation Loss: 3.8700, Validation Acc: 0.0835\n","Epoch 4 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.8556, Train Acc: 0.0909\n","Validation Loss: 3.7192, Validation Acc: 0.1075\n","Epoch 5 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.7451, Train Acc: 0.1087\n","Validation Loss: 3.6097, Validation Acc: 0.1353\n","Epoch 6 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.6342, Train Acc: 0.1285\n","Validation Loss: 3.5042, Validation Acc: 0.1534\n","Epoch 7 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.5334, Train Acc: 0.1486\n","Validation Loss: 3.4373, Validation Acc: 0.1644\n","Epoch 8 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.4550, Train Acc: 0.1654\n","Validation Loss: 3.3433, Validation Acc: 0.1826\n","Epoch 9 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.3574, Train Acc: 0.1787\n","Validation Loss: 3.2398, Validation Acc: 0.1993\n","Epoch 10 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.2745, Train Acc: 0.1944\n","Validation Loss: 3.1761, Validation Acc: 0.2067\n","Epoch 11 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.0761, Train Acc: 0.2349\n","Validation Loss: 2.9863, Validation Acc: 0.2480\n","Epoch 12 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 3.0160, Train Acc: 0.2440\n","Validation Loss: 2.9546, Validation Acc: 0.2565\n","Epoch 13 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.9784, Train Acc: 0.2503\n","Validation Loss: 2.9403, Validation Acc: 0.2619\n","Epoch 14 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.9559, Train Acc: 0.2576\n","Validation Loss: 2.9157, Validation Acc: 0.2644\n","Epoch 15 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.9384, Train Acc: 0.2574\n","Validation Loss: 2.8980, Validation Acc: 0.2723\n","Epoch 16 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.9112, Train Acc: 0.2670\n","Validation Loss: 2.8959, Validation Acc: 0.2684\n","Epoch 17 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.8972, Train Acc: 0.2667\n","Validation Loss: 2.8548, Validation Acc: 0.2775\n","Epoch 18 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.8718, Train Acc: 0.2723\n","Validation Loss: 2.8373, Validation Acc: 0.2821\n","Epoch 19 [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■] - Train Loss: 2.8520, Train Acc: 0.2774\n","Validation Loss: 2.8451, Validation Acc: 0.2793\n","Epoch 20 [■■■■■■■■■■■■■■□□□□□□□□□□□□□□□□□]"]}],"source":["# for CIFAR-10, CIFAR-100\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import model_loader\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import datasets, transforms\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","num_epochs = 30\n","batch_size = 128\n","\n","# augment *padding *HorizontalFlip\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    transforms.Resize((224, 224))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    transforms.Resize((224, 224))\n","])\n","\n","# Call CIFAR datasets\n","train_dataset = datasets.CIFAR100('./train', train=True, transform=transform_train, download=True)\n","val_dataset = datasets.CIFAR100('./train', train=True, transform=transform_test, download=True)\n","test_dataset = datasets.CIFAR100('./test', train=False, transform=transform_test, download=True)\n","\n","# Split train datasets for validation datasets\n","num_train = len(train_dataset)\n","indices = list(range(num_train))\n","split = int(np.floor(0.2 * num_train))\n","train_idx, val_idx = indices[split:], indices[:split]\n","\n","val_sampler = SubsetRandomSampler(val_idx)\n","np.random.shuffle(indices)\n","train_sampler = SubsetRandomSampler(train_idx)\n","\n","# Create DataLoader (split by batch size)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, sampler=val_sampler)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","cnt_progress = len(train_loader) // 30\n","\n","model_name ='effnetv2_l'\n","model = model_loader.load(model_name, num_class=100).to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n","loss_func = nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1)\n","\n","best_val_loss = float('Inf')\n","train_loss = []\n","val_loss = []\n","train_acc = []\n","val_acc = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_acc = 0\n","    total_train_loss = 0\n","    for cnt, (images_, labels_) in enumerate(train_loader):\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","        loss = loss_func(predict, labels.long())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_acc += (predict.argmax(1) == labels).float().mean().item()\n","        total_train_loss += loss.item()\n","        # progress bar 구현\n","        if cnt % cnt_progress == 0:\n","            print(f'\\rEpoch {epoch + 1} [', end='')\n","            for prog in range(cnt // cnt_progress):\n","                print('■', end='')\n","            for prog in range((len(train_loader) - cnt) // cnt_progress):\n","                print('□', end='')\n","            print(']', end='')\n","\n","    total_train_loss /= len(train_loader)\n","    total_train_acc /= len(train_loader)\n","    train_loss.append(total_train_loss)\n","    train_acc.append(total_train_acc)\n","    print(f' - Train Loss: {total_train_loss:.4f}, Train Acc: {total_train_acc:.4f}')\n","\n","    model.eval()  # 모델을 평가 모드로 설정\n","    total_val_acc = 0\n","    total_val_loss = 0\n","    with torch.no_grad():\n","        for images_, labels_ in val_loader:\n","            images = images_.to(device)\n","            labels = labels_.to(device)\n","\n","            predict = model(images)\n","            acc = (predict.argmax(1) == labels).float().mean().item()\n","            loss = loss_func(predict, labels.long())\n","            total_val_acc += acc\n","            total_val_loss += loss.item()\n","\n","        total_val_loss /= len(val_loader)\n","        total_val_acc /= len(val_loader)\n","\n","    val_loss.append(total_val_loss)\n","    val_acc.append(total_val_acc)\n","    print(f'Validation Loss: {total_val_loss:.4f}, Validation Acc: {total_val_acc:.4f}')\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","\n","    scheduler.step()\n","\n","model.load_state_dict(torch.load('best_model.pt'))\n","model.eval()\n","\n","total_test_acc = 0\n","total_test_loss = 0\n","with torch.no_grad():\n","    for images_, labels_ in test_loader:\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","\n","        acc = (predict.argmax(1) == labels).float().mean().item()\n","        loss = loss_func(predict, labels.long())\n","\n","        total_test_acc += acc\n","        total_test_loss += loss.item()\n","\n","    total_test_loss /= len(test_loader)\n","    total_test_acc /= len(test_loader)\n","\n","print(f'Test Loss: {total_test_loss:.4f}, Test Acc: {total_test_acc:.4f}')\n","\n","# plot Loss Graph\n","plt.subplot(2, 1, 1)\n","plt.plot(train_loss)\n","plt.plot(val_loss)\n","plt.title('model loss')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.ylim(0, 2)\n","plt.legend(['train', 'validation'], loc='upper left')\n","# plot Acc Graph\n","plt.subplot(2, 1, 2)\n","plt.plot(np.array(train_acc) * 100)\n","plt.plot(np.array(val_acc) * 100)\n","plt.title('model acc')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.ylim(0, 100)\n","plt.legend(['train', 'validation'], loc='upper left')\n","\n","plt.tight_layout()\n","plt.savefig(f'graphs/{model_name}_residual.png')\n","\n","model = model.to(\"cpu\")\n","torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[],"machine_shape":"hm","mount_file_id":"1jN8-zFnQfzo8rhOnwKJTOMCqA_0u9KU0","authorship_tag":"ABX9TyP8Q/YZuzKA33ta/oPHEKFb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}