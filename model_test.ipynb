{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20170,"status":"ok","timestamp":1713196879180,"user":{"displayName":"지찬웅","userId":"10324921424986400402"},"user_tz":-540},"id":"DZ98ZS0bbt49","outputId":"636392cf-57c1-4e88-f648-f8c0427f9d17"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713257975404,"user":{"displayName":"지찬웅","userId":"10324921424986400402"},"user_tz":-540},"id":"SUpaugFob5Ku","outputId":"c1e05000-7af0-4132-fd0a-c632d933fc2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/github/PBL\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/github/PBL"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"id":"k9l57rG9Zoud","outputId":"4d1fabbb-d5cd-498c-a232-d3fe3c471eb0","executionInfo":{"status":"error","timestamp":1713266251583,"user_tz":-540,"elapsed":8543,"user":{"displayName":"지찬웅","userId":"10324921424986400402"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch 1 [□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□]"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-5af11a443349>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mtotal_train_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# progress bar 구현\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# for CIFAR-10, CIFAR-100\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import model_loader\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import datasets, transforms\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","num_epochs = 20\n","batch_size = 128\n","\n","# augment *padding *HorizontalFlip\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n","    transforms.Resize((224, 224))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.CenterCrop(32),\n","    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n","    transforms.Resize((224, 224))\n","])\n","\n","# Call CIFAR datasets\n","train_dataset = datasets.CIFAR100('./train', train=True, transform=transform_train, download=True)\n","val_dataset = datasets.CIFAR100('./train', train=True, transform=transform_test, download=True)\n","test_dataset = datasets.CIFAR100('./test', train=False, transform=transform_test, download=True)\n","\n","# Split train datasets for validation datasets\n","num_train = len(train_dataset)\n","indices = list(range(num_train))\n","split = int(np.floor(0.2 * num_train))\n","train_idx, val_idx = indices[split:], indices[:split]\n","\n","val_sampler = SubsetRandomSampler(val_idx)\n","np.random.shuffle(indices)\n","train_sampler = SubsetRandomSampler(train_idx)\n","\n","# Create DataLoader (split by batch size)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, sampler=val_sampler)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","cnt_progress = len(train_loader) // 30\n","\n","model_name ='effnetv2_s'\n","model = model_loader.load(model_name, num_class=100).to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.005, amsgrad=False)\n","loss_func = nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, max_lr=0.001, epochs=num_epochs, steps_per_epoch=len(train_loader))\n","# lr_s = 0.001 lr_m = 0.005 lr_l = 0.003\n","\n","best_val_loss = float('Inf')\n","train_loss = []\n","val_loss = []\n","train_acc = []\n","val_acc = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_acc = 0\n","    total_train_loss = 0\n","    for cnt, (images_, labels_) in enumerate(train_loader):\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","        loss = loss_func(predict, labels.long())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_acc += (predict.argmax(1) == labels).float().mean().item()\n","        total_train_loss += loss.item()\n","        # progress bar 구현\n","        if cnt % cnt_progress == 0:\n","            print(f'\\rEpoch {epoch + 1} [', end='')\n","            for prog in range(cnt // cnt_progress):\n","                print('■', end='')\n","            for prog in range((len(train_loader) - cnt) // cnt_progress):\n","                print('□', end='')\n","            print(']', end='')\n","\n","    total_train_loss /= len(train_loader)\n","    total_train_acc /= len(train_loader)\n","    train_loss.append(total_train_loss)\n","    train_acc.append(total_train_acc)\n","    print(f' - Train Loss: {total_train_loss:.4f}, Train Acc: {total_train_acc:.4f}')\n","\n","    model.eval()  # 모델을 평가 모드로 설정\n","    total_val_acc = 0\n","    total_val_loss = 0\n","    num_loss = 0\n","    with torch.no_grad():\n","        for images_, labels_ in val_loader:\n","            images = images_.to(device)\n","            labels = labels_.to(device)\n","\n","            predict = model(images)\n","            acc = (predict.argmax(1) == labels).float().mean().item()\n","            loss = loss_func(predict, labels.long())\n","            total_val_acc += acc\n","            total_val_loss += loss.item()\n","\n","        total_val_loss /= len(val_loader)\n","        total_val_acc /= len(val_loader)\n","\n","    val_loss.append(total_val_loss)\n","    val_acc.append(total_val_acc)\n","\n","    if total_val_loss < best_val_loss:\n","        num_loss = 0\n","        best_val_loss = total_val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","    else:\n","        num_loss += 1\n","        if num_loss == 5:\n","            print(f'early stopping: epoch {epoch}')\n","            break\n","    val_loss.append(total_val_loss)\n","    val_acc.append(total_val_acc)\n","    print(f'Validation Loss: {total_val_loss:.4f}, Validation Acc: {total_val_acc:.4f}')\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","\n","    scheduler.step()\n","\n","model.load_state_dict(torch.load('best_model.pt'))\n","model.eval()\n","\n","total_test_acc = 0\n","total_test_loss = 0\n","with torch.no_grad():\n","    for images_, labels_ in test_loader:\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","\n","        acc = (predict.argmax(1) == labels).float().mean().item()\n","        loss = loss_func(predict, labels.long())\n","\n","        total_test_acc += acc\n","        total_test_loss += loss.item()\n","\n","    total_test_loss /= len(test_loader)\n","    total_test_acc /= len(test_loader)\n","\n","print(f'Test Loss: {total_test_loss:.4f}, Test Acc: {total_test_acc:.4f}')\n","\n","# plot Loss Graph\n","plt.subplot(2, 1, 1)\n","plt.plot(train_loss)\n","plt.plot(val_loss)\n","plt.title('model loss')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.ylim(0, 2)\n","plt.legend(['train', 'validation'], loc='upper left')\n","# plot Acc Graph\n","plt.subplot(2, 1, 2)\n","plt.plot(np.array(train_acc) * 100)\n","plt.plot(np.array(val_acc) * 100)\n","plt.title('model acc')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.ylim(0, 100)\n","plt.legend(['train', 'validation'], loc='upper left')\n","\n","plt.tight_layout()\n","plt.savefig(f'graphs/{model_name}_residual.png')\n","\n","model = model.to(\"cpu\")\n","torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"1jN8-zFnQfzo8rhOnwKJTOMCqA_0u9KU0","authorship_tag":"ABX9TyN27Qh1g89eYloD0fc9H4xL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}