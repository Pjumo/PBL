{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20106,"status":"ok","timestamp":1713189998048,"user":{"displayName":"지찬웅","userId":"10324921424986400402"},"user_tz":-540},"id":"DZ98ZS0bbt49","outputId":"9a76ef62-3390-49ea-f9e6-75d73e35fa6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1713190042218,"user":{"displayName":"지찬웅","userId":"10324921424986400402"},"user_tz":-540},"id":"SUpaugFob5Ku","outputId":"d5665ec2-70b0-4055-aea7-630c1a1171b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/github/PBL\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/github/PBL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9l57rG9Zoud","outputId":"f6c65800-967f-4207-fc5f-6baa932dc186"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch 1 [■■■■■■■■■□□□□□□□□□□□□□□□□□□□□□□]"]}],"source":["# for CIFAR-10, CIFAR-100\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import model_loader\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import datasets, transforms\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","num_epochs = 30\n","batch_size = 64\n","\n","# augment *padding *HorizontalFlip\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5074, 0.4867, 0.4411), (0.2011, 0.1987, 0.2025)),\n","    transforms.Resize((224, 224))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5074, 0.4867, 0.4411), (0.2011, 0.1987, 0.2025)),\n","    transforms.Resize((224, 224))\n","])\n","\n","# Call CIFAR datasets\n","train_dataset = datasets.CIFAR100('./train', train=True, transform=transform_train, download=True)\n","val_dataset = datasets.CIFAR100('./train', train=True, transform=transform_test, download=True)\n","test_dataset = datasets.CIFAR100('./test', train=False, transform=transform_test, download=True)\n","\n","# Split train datasets for validation datasets\n","num_train = len(train_dataset)\n","indices = list(range(num_train))\n","split = int(np.floor(0.2 * num_train))\n","train_idx, val_idx = indices[split:], indices[:split]\n","\n","val_sampler = SubsetRandomSampler(val_idx)\n","np.random.shuffle(indices)\n","train_sampler = SubsetRandomSampler(train_idx)\n","\n","# Create DataLoader (split by batch size)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, sampler=val_sampler)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","cnt_progress = len(train_loader) // 30\n","\n","model_name ='effnetv2_s'\n","model = model_loader.load(model_name, num_class=100).to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=False)\n","loss_func = nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1)\n","\n","best_val_loss = float('Inf')\n","train_loss = []\n","val_loss = []\n","train_acc = []\n","val_acc = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_acc = 0\n","    total_train_loss = 0\n","    for cnt, (images_, labels_) in enumerate(train_loader):\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","        loss = loss_func(predict, labels.long())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_acc += (predict.argmax(1) == labels).float().mean().item()\n","        total_train_loss += loss.item()\n","        # progress bar 구현\n","        if cnt % cnt_progress == 0:\n","            print(f'\\rEpoch {epoch + 1} [', end='')\n","            for prog in range(cnt // cnt_progress):\n","                print('■', end='')\n","            for prog in range((len(train_loader) - cnt) // cnt_progress):\n","                print('□', end='')\n","            print(']', end='')\n","\n","    total_train_loss /= len(train_loader)\n","    total_train_acc /= len(train_loader)\n","    train_loss.append(total_train_loss)\n","    train_acc.append(total_train_acc)\n","    print(f' - Train Loss: {total_train_loss:.4f}, Train Acc: {total_train_acc:.4f}')\n","\n","    model.eval()  # 모델을 평가 모드로 설정\n","    total_val_acc = 0\n","    total_val_loss = 0\n","    num_loss = 0\n","    with torch.no_grad():\n","        for images_, labels_ in val_loader:\n","            images = images_.to(device)\n","            labels = labels_.to(device)\n","\n","            predict = model(images)\n","            acc = (predict.argmax(1) == labels).float().mean().item()\n","            loss = loss_func(predict, labels.long())\n","            total_val_acc += acc\n","            total_val_loss += loss.item()\n","\n","        total_val_loss /= len(val_loader)\n","        total_val_acc /= len(val_loader)\n","\n","    val_loss.append(total_val_loss)\n","    val_acc.append(total_val_acc)\n","    print(f'Validation Loss: {total_val_loss:.4f}, Validation Acc: {total_val_acc:.4f}')\n","\n","    if total_val_loss < best_val_loss:\n","        num_loss = 0\n","        best_val_loss = total_val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","    else:\n","        num_loss += 1\n","        if num_loss == 5:\n","            print(f'early stopping: epoch {epoch}')\n","            break\n","    val_loss.append(total_val_loss)\n","    val_acc.append(total_val_acc)\n","    print(f'Validation Loss: {total_val_loss:.4f}, Validation Acc: {total_val_acc:.4f}')\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","\n","    scheduler.step()\n","\n","model.load_state_dict(torch.load('best_model.pt'))\n","model.eval()\n","\n","total_test_acc = 0\n","total_test_loss = 0\n","with torch.no_grad():\n","    for images_, labels_ in test_loader:\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","\n","        acc = (predict.argmax(1) == labels).float().mean().item()\n","        loss = loss_func(predict, labels.long())\n","\n","        total_test_acc += acc\n","        total_test_loss += loss.item()\n","\n","    total_test_loss /= len(test_loader)\n","    total_test_acc /= len(test_loader)\n","\n","print(f'Test Loss: {total_test_loss:.4f}, Test Acc: {total_test_acc:.4f}')\n","\n","# plot Loss Graph\n","plt.subplot(2, 1, 1)\n","plt.plot(train_loss)\n","plt.plot(val_loss)\n","plt.title('model loss')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.ylim(0, 2)\n","plt.legend(['train', 'validation'], loc='upper left')\n","# plot Acc Graph\n","plt.subplot(2, 1, 2)\n","plt.plot(np.array(train_acc) * 100)\n","plt.plot(np.array(val_acc) * 100)\n","plt.title('model acc')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.ylim(0, 100)\n","plt.legend(['train', 'validation'], loc='upper left')\n","\n","plt.tight_layout()\n","plt.savefig(f'graphs/{model_name}_residual.png')\n","\n","model = model.to(\"cpu\")\n","torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyO1i95OGMx5qrt1F/t6D++t"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}