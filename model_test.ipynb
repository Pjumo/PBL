{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"19DZdaHQOtZluMw2Gx-ed0oJRD-42ppPv","authorship_tag":"ABX9TyNowrhHuZW0SIwHaYTMVCVT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZ98ZS0bbt49","executionInfo":{"status":"ok","timestamp":1712558394871,"user_tz":-540,"elapsed":13333,"user":{"displayName":"지찬웅","userId":"10324921424986400402"}},"outputId":"52b2e600-e211-4ad6-c3ce-605c8254a577"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd PBL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUpaugFob5Ku","executionInfo":{"status":"ok","timestamp":1712558596221,"user_tz":-540,"elapsed":5,"user":{"displayName":"지찬웅","userId":"10324921424986400402"}},"outputId":"f222af01-44ae-4e8f-d1c0-16a443e10013"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab/PBL2/PBL\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"id":"k9l57rG9Zoud","executionInfo":{"status":"error","timestamp":1712558642886,"user_tz":-540,"elapsed":42682,"user":{"displayName":"지찬웅","userId":"10324921424986400402"}},"outputId":"f81d738e-8bee-419d-d786-c7b45bfb9f92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 77379515.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./train/cifar-10-python.tar.gz to ./train\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./test/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 77726020.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./test/cifar-10-python.tar.gz to ./test\n","Epoch 1 [□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□]"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1b6efed04d72>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# for CIFAR-10, CIFAR-100\n","\n","import numpy as np\n","import model_loader\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import datasets, transforms\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","num_epochs = 10\n","batch_size = 32\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Call CIFAR datasets\n","train_dataset = datasets.CIFAR10('./train', train=True, transform=transform, download=True)\n","test_dataset = datasets.CIFAR10('./test', train=False, transform=transform, download=True)\n","\n","# Split train datasets for validation datasets\n","num_train = len(train_dataset)\n","indices = list(range(num_train))\n","split = int(np.floor(0.2 * num_train))\n","train_idx, val_idx = indices[split:], indices[:split]\n","np.random.shuffle(indices)\n","\n","train_sampler = SubsetRandomSampler(train_idx)\n","val_sampler = SubsetRandomSampler(val_idx)\n","\n","# Create DataLoader (split by batch size)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n","val_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=val_sampler)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","cnt_progress = len(train_loader)//30\n","\n","model = model_loader.load('resnet18', num_class=10).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer=optimizer,\n","    lr_lambda=lambda epoch_: 0.95 ** epoch_,\n","    last_epoch=-1)\n","\n","best_val_loss = float('Inf')\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_acc = 0\n","    total_train_loss = 0\n","    for cnt, (images_, labels_) in enumerate(train_loader):\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","        loss = loss_func(predict, labels.long())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_acc += (predict.argmax(1) == labels).float().mean().item()\n","        total_train_loss += loss.item()\n","        if cnt % cnt_progress == 0:\n","            print(f'\\rEpoch {epoch + 1} [', end='')\n","            for prog in range(cnt // cnt_progress):\n","                print('■', end='')\n","            for prog in range((len(train_loader) - cnt) // cnt_progress):\n","                print('□', end='')\n","            print(']', end='')\n","\n","    total_train_loss /= len(train_loader)\n","    total_train_acc /= len(train_loader)\n","    print(f' - Train Loss: {total_train_loss:.4f}, Train Acc: {total_train_acc:.4f}')\n","\n","    model.eval()  # 모델을 평가 모드로 설정\n","    total_val_acc = 0\n","    total_val_loss = 0\n","    with torch.no_grad():\n","        for images_, labels_ in val_loader:\n","            images = images_.to(device)\n","            labels = labels_.to(device)\n","\n","            predict = model(images)\n","            acc = (predict.argmax(1) == labels).float().mean().item()\n","            loss = loss_func(predict, labels.long())\n","            total_val_acc += acc\n","            total_val_loss += loss.item()\n","\n","        total_val_loss /= len(val_loader)\n","        total_val_acc /= len(val_loader)\n","\n","    print(f'Validation Loss: {total_val_loss:.4f}, Validation Acc: {total_val_acc:.4f}')\n","\n","    if total_val_loss < best_val_loss:\n","        best_val_loss = total_val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","\n","    scheduler.step()\n","\n","model.load_state_dict(torch.load('best_model.pt'))\n","model.eval()\n","\n","total_test_acc = 0\n","total_test_loss = 0\n","with torch.no_grad():\n","    for images_, labels_ in test_loader:\n","        images = images_.to(device)\n","        labels = labels_.to(device)\n","\n","        predict = model(images)\n","\n","        acc = (predict.argmax(1) == labels).float().mean().item()\n","        loss = loss_func(predict, labels.long())\n","\n","        total_test_acc += acc\n","        total_test_loss += loss.item()\n","\n","    total_test_loss /= len(test_loader)\n","    total_test_acc /= len(test_loader)\n","\n","print(f'Test Loss: {total_test_loss:.4f}, Test Acc: {total_test_acc:.4f}')\n","\n","model = model.to(\"cpu\")\n","torch.cuda.empty_cache()"]}]}